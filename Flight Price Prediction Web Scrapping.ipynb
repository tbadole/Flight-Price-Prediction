{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0061668",
   "metadata": {},
   "source": [
    "# Web Scrapping (Data Collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79ee673",
   "metadata": {},
   "source": [
    "You have to scrape at least 1500 rows of data. You can scrape more data as well, it’s up to you, More the data better the model In this section you have to scrape the data of flights from different websites (yatra.com, skyscanner.com, official websites of airlines, etc). The number of columns for data doesn’t have limit, it’s up to you and your creativity. Generally, these columns are airline name, date of journey, source, destination, route, departure time, arrival time, duration, total stops and the target variable price. You can make changes to it, you can add or you can remove some columns, it completely depends on the website from which you are fetching the data.\n",
    "\n",
    "airline name, date of journey, source, destination, departure time, arrival time, duration, total stops and the target variable price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a92c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries/Dependencies\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "import re\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import ElementNotVisibleException\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609d0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to the webdriver \n",
    "driver = webdriver.Chrome(\"C:\\web driver\\chromedriver.exe\")\n",
    "driver.maximize_window()        # Maximizing the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cffeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url\n",
    "url = \"https://flight.yatra.com/air-search-ui/dom2/trigger?type=O&viewName=normal&flexi=0&noOfSegments=1&origin=GOI&originCountry=IN&destination=BOM&destinationCountry=IN&flight_depart_date=05%2F08%2F2022&ADT=1&CHD=0&INF=0&class=Economy&source=fresco-home&unqvaldesktop=846570657840\"\n",
    "driver.get(url)\n",
    "time.sleep(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d95832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a list of locations to scrap data\n",
    "loc_lst = ['New Delhi', 'Mumbai', 'Bangalore', 'Chennai','Hyderabad ','Goa ','Kolkata ','Jaipur ','Lucknow ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72143b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists to fetch required data\n",
    "\n",
    "Airline_name=[]      # The name of the airline.\n",
    "Departure_time = []  # The time when the journey starts from the source.\n",
    "Arrival_time = []    # Time of arrival at the destination.\n",
    "Duration=[]          # Total duration taken by the flight to reach the destination from the source.\n",
    "Stops = []           # Total stops between the source and destination.\n",
    "Source = []          # The source from which the service begins.\n",
    "Destination = []     # The destination where the service ends.\n",
    "Meal=[]              # Availability of meals in the flight.\n",
    "Price=[]             # The price of the flight ticket.\n",
    "Location=[]          # The location of the flights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15165bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping the data from the mentioned url\n",
    "\n",
    "# Fetching webelement of source \n",
    "for x in loc_lst:\n",
    "    for y in loc_lst:\n",
    "        if x!=y:                 \n",
    "            Source = driver.find_element_by_xpath(\"//div[@class='input-holder pb-2 bdr-btm']/input\")\n",
    "            time.sleep(2)\n",
    "            Source.clear() \n",
    "            Source.send_keys(x)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Fetching webelement of destination\n",
    "            Destination = driver.find_element_by_xpath(\"//div[@class='input-holder  bdr-btm pb-2']/input\")\n",
    "            Destination.click()\n",
    "            Destination.clear()\n",
    "            time.sleep(2)\n",
    "            Destination.send_keys(y)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Searching for flights again and clicking in search again button\n",
    "            try:\n",
    "                srch_btn = driver.find_element_by_xpath(\"//button[@class='fs-14 btn-submit cursor-pointer bold']\")\n",
    "                wait = WebDriverWait(driver, 10)\n",
    "                wait.until(EC.visibility_of(srch_btn))\n",
    "                srch_btn.click()\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Scrolling the data 5000 times \n",
    "            for _ in range(15):\n",
    "                time.sleep(1)\n",
    "                driver.execute_script(\"window.scrollBy(0,5000)\")\n",
    "                time.sleep(5)\n",
    "            \n",
    "            # Fetching web element of scroll to top button\n",
    "            try:\n",
    "                driver.find_element_by_xpath(\"//div[@title='scroll to top']\").click()\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "           # Fetching name of Airline\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='fs-13 airline-name no-pad col-8']/span\"):\n",
    "                    Airline_name.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching departure time of the flights\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='i-b pr']\"):\n",
    "                    Departure_time.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching arrival time of the flights \n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='i-b pdd-0 text-left atime col-5']//p[1]\"):\n",
    "                    Arrival_time.append(i.get_attribute(\"innerHTML\").splitlines()[0][0:5])\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching Duration of flights journey\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='stop-cont pl-13']/p\"):\n",
    "                    Duration.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching number of stops the flights have between source and destination\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class=' font-lightgrey fs-10 tipsy i-b fs-10']/span[1]\"):\n",
    "                    Stops.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching availability of meal in flights\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='features pull-right fs-12 flex']/div[1]\"):\n",
    "                    Meal.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching Locations\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//p[@class='fs-10 font-lightgrey no-wrap city ellipsis']\"):\n",
    "                    Location.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "            \n",
    "            # Fetching Prices of flight tickets\n",
    "            try:\n",
    "                for i in driver.find_elements_by_xpath(\"//div[@class='i-b tipsy fare-summary-tooltip fs-18']\"):\n",
    "                    Price.append(i.text)\n",
    "            except NoSuchElementException:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898d5b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Source = Location[0:len(Location):2]\n",
    "Destination = Location[1:len(Location):2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking length of source and destination\n",
    "len(Source), len(Destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c543fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking lengths of all features\n",
    "print(len(Price),len(Airline_name),len(Departure_time),len(Arrival_time),len(Duration),len(Stops),len(Meal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d1c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dataframe for scraped data\n",
    "data = list(zip(Airline_name,Departure_time,Arrival_time,Duration,Source,Destination,Meal,Stops,Price))\n",
    "df = pd.DataFrame(data, columns = [\"Airline\",\"Departure_time\",\"Time_of_arrival\",\"Duration\", \"Source\",\"Destination\",\"Meal_availability\",\"Number_of_stops\",\"Price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69218053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef2ba31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the data into excel file\n",
    "df.to_excel(\"Flight_Prices.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc82480",
   "metadata": {},
   "source": [
    "I have successfully scraped the required data from the website yatra.com. The dataframe consists of 5303 rows and 9 columns. And I have saved this dataframe in excel format as \"Flight_Prices\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81992a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
